{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae90ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4349a",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f685790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33631108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 5명의 데이터가 모였습니다!!\n",
      "rock에 501개 \n",
      "scissor에 501개 \n",
      "paper에 501개 \n"
     ]
    }
   ],
   "source": [
    "#유저 여러명 데이터 모으기\n",
    "base_dir=os.getenv(\"HOME\")+'/aiffel/Exploration/EX1/data/other_users/'\n",
    "members = ['정우', '진영', '현지', '서현']\n",
    "# members = os.listdir(base_dir)\n",
    "categories = ['rock', 'scissor', 'paper']\n",
    "base_dst = os.getenv(\"HOME\")+'/aiffel/Exploration/EX1/data/data_all_users/'\n",
    "\n",
    "for member in members:\n",
    "    for category in categories:\n",
    "        path = os.path.join(base_dir, member, category)\n",
    "        for image in os.listdir(path):\n",
    "            if \".jpg\" in image:\n",
    "                image_rename = member + '_' + image\n",
    "                image_path_src = os.path.join(base_dir, member, category, image)\n",
    "                image_path_dst = os.path.join(base_dst, category, image_rename)\n",
    "                shutil.copyfile(image_path_src, image_path_dst)\n",
    "\n",
    "\n",
    "\n",
    "#본인 데이터 트레인 셋에 추가\n",
    "base_dir = os.getenv(\"HOME\")+'/aiffel/Exploration/EX1/data/rock_scissor_paper'\n",
    "for category in categories:\n",
    "    path = os.path.join(base_dir, category)\n",
    "    for image in os.listdir(path):\n",
    "        if '.jpg' in image:\n",
    "            image_rename = '현빈_' + image\n",
    "            image_path_src = os.path.join(base_dir, category, image)\n",
    "            image_path_dst = os.path.join(base_dst, category, image_rename)\n",
    "            shutil.copyfile(image_path_src, image_path_dst)\n",
    "            \n",
    "            \n",
    "print(f\"총 {len(members)+1}명의 데이터가 모였습니다!!\")\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"{category}에 {len(os.listdir(base_dst+category))}개 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79af95ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "500  images to be resized.\n",
      "500  images resized.\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터 크기 28x28로 조정\n",
    "for class_ in [\"rock\", \"scissor\", \"paper\"]:\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel/Exploration/EX1/data/data_all_users/\" + class_\n",
    "    resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ae2c9",
   "metadata": {},
   "source": [
    "## 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc74a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2bfd28be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 28, 28, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/Exploration/EX1/data/data_all_users\"\n",
    "(x_train, y_train)=load_data(image_dir_path, (len(members)+1)*300) #추가한 사진들의 수에 맞게\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151eeb67",
   "metadata": {},
   "source": [
    "### 이미지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8123591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaffd17",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7ad3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 10, 10, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 142,915\n",
      "Trainable params: 142,595\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(128, (3,3), input_shape=(28,28,3)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('swish'))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='swish'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3,3) ))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('swish'))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='swish'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "#model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='swish'))\n",
    "#model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(64, activation='swish'))\n",
    "#model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd22b68",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1130c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "47/47 [==============================] - 1s 8ms/step - loss: 1.0282 - accuracy: 0.4573\n",
      "Epoch 2/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.7557 - accuracy: 0.6587\n",
      "Epoch 3/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.6004 - accuracy: 0.7393\n",
      "Epoch 4/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.8087\n",
      "Epoch 5/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.3426 - accuracy: 0.8660\n",
      "Epoch 6/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.9013\n",
      "Epoch 7/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.2596 - accuracy: 0.9033\n",
      "Epoch 8/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1814 - accuracy: 0.9313\n",
      "Epoch 9/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9460\n",
      "Epoch 10/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.9687\n",
      "Epoch 11/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1314 - accuracy: 0.9507\n",
      "Epoch 12/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9833\n",
      "Epoch 13/13\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.1005 - accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff71473cfa0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "#콜백 함수\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, callbacks = [model_checkpoint_callback], epochs=13)\n",
    "model.load_weights(checkpoint_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24aac7",
   "metadata": {},
   "source": [
    "## Test Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97aa7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "#Resizing\n",
    "for class_ in [\"rock\", \"scissor\", \"paper\"]:\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel/Exploration/EX1/data/rock_scissor_paper_given/test/\" + class_\n",
    "    resize_images(image_dir_path)\n",
    "    \n",
    "\n",
    "#Loading                  \n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/Exploration/EX1/data/rock_scissor_paper_given/test\"\n",
    "                  \n",
    "(x_test, y_test)=load_data(image_dir_path, 300)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8d936",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3c8e6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.3894 - accuracy: 0.7167\n",
      "test_loss: 1.3893829584121704 \n",
      "test_accuracy: 0.7166666388511658\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d82d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
